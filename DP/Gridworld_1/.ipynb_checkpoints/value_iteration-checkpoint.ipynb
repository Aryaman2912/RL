{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize states and random policy\n",
    "\n",
    "def initialization():\n",
    "    '''\n",
    "    Returns:\n",
    "            V - a 2d array initialized as 0\n",
    "            R - dictionary containing rewards for each state\n",
    "            P - dictionary denoting equiprobable random policy\n",
    "            states - array containing tuples of states in the gridworld\n",
    "            terminal_states - array containing terminal states of the gridworld\n",
    "    '''\n",
    "    num_rows = 4\n",
    "    num_cols = 4\n",
    "    states = []\n",
    "    for i in range(num_rows):\n",
    "        for j in range(num_cols):\n",
    "            states.append((i,j))\n",
    "    terminal_states = [(0,0),(3,3)]\n",
    "    V = np.zeros([4,4])\n",
    "    R = {}\n",
    "    P = {}\n",
    "    for state in states:\n",
    "        if state in terminal_states:\n",
    "            R[state] = 0\n",
    "            P[state] = []\n",
    "        else:\n",
    "            R[state] = -1\n",
    "            P[state] = ['L','R','D','U']\n",
    "    return V,R,P,states,terminal_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to implement Value iteration\n",
    "def value_iteration(V,P,R,states,terminal_states):\n",
    "    '''\n",
    "    Arguments:\n",
    "            V - a 2d array initialized as 0\n",
    "            R - dictionary containing rewards for each state\n",
    "            P - dictionary denoting equiprobable random policy\n",
    "            states - array containing tuples of states in the gridworld\n",
    "            terminal_states - array containing terminal states of the gridworld\n",
    "    Returns:\n",
    "            P - optimal policy\n",
    "    '''\n",
    "    Actions = [[0,-1,'L'],[-1,0,'U'],[0,1,'R'],[1,0,'D']]\n",
    "    num_iterations = 0\n",
    "\n",
    "    # Loop for convergence of value function\n",
    "    while num_iterations < 1000:\n",
    "        \n",
    "        V1 = {}\n",
    "        for state in states:\n",
    "            if state in terminal_states:\n",
    "                V1[state] = 0\n",
    "                continue\n",
    "            V1[state] = -1e10\n",
    "            \n",
    "        # Evaluate value of each state using DP methods\n",
    "        for state in states:\n",
    "            if state in terminal_states:\n",
    "                continue\n",
    "            moves = len(P[state])\n",
    "            for a in Actions:\n",
    "                (x,y) = (state[0] + a[0],state[1] + a[1])\n",
    "                if x in range(4) and y in range(4):\n",
    "                    V1[state] = max(V1[state],(R[state] + V[(x,y)]))    \n",
    "                    \n",
    "        V = V1\n",
    "        num_iterations += 1\n",
    "        \n",
    "    # Find optimal policy using precomputed values of all states \n",
    "    for state in states:\n",
    "        if state in terminal_states:\n",
    "            continue\n",
    "        optimal_policy = []\n",
    "        max_val = -1e10\n",
    "        for a in Actions:\n",
    "            (x,y) = (state[0] + a[0],state[1] + a[1])\n",
    "            if x in range(4) and y in range(4):\n",
    "                val = -1 + V[(x,y)]\n",
    "                if val > max_val:\n",
    "                    max_val = val\n",
    "                    optimal_policy = [a[2]]\n",
    "                elif val == max_val:\n",
    "                    optimal_policy.append(a[2])\n",
    "        P[state] = optimal_policy\n",
    "        \n",
    "\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal policy is: \n",
      "[] ['L'] ['L'] ['L', 'D'] \n",
      "['U'] ['L', 'U'] ['L', 'U', 'R', 'D'] ['D'] \n",
      "['U'] ['L', 'U', 'R', 'D'] ['R', 'D'] ['D'] \n",
      "['U', 'R'] ['R'] ['R'] [] \n"
     ]
    }
   ],
   "source": [
    "V,R,P,states,terminal_states = initialization()\n",
    "P = value_iteration(V,P,R,states,terminal_states)\n",
    "\n",
    "# Print optimal policy\n",
    "# Each cell denotes the optimal action that needs to be taken in that state\n",
    "print(\"Optimal policy is: \")\n",
    "for row in range(4):\n",
    "    for col in range(4):\n",
    "        print(P[(row,col)],end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
