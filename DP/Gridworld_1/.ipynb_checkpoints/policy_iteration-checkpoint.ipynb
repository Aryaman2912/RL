{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization():\n",
    "    '''\n",
    "    Returns:\n",
    "            V - a 2d array initialized as 0\n",
    "            R - array containing rewards for each state\n",
    "            P - array denoting equiprobable random policy\n",
    "            states - array containing tuples of states in the gridworld\n",
    "            terminal_states - array containing terminal states of the gridworld\n",
    "    '''\n",
    "    num_rows = 4\n",
    "    num_cols = 4\n",
    "    states = []\n",
    "    for i in range(num_rows):\n",
    "        for j in range(num_cols):\n",
    "            states.append((i,j))\n",
    "    terminal_states = [(0,0),(3,3)]\n",
    "    V = np.zeros([4,4])\n",
    "    R = {}\n",
    "    P = {}\n",
    "    for state in states:\n",
    "        if state in terminal_states:\n",
    "            R[state] = 0\n",
    "            P[state] = []\n",
    "        else:\n",
    "            R[state] = -1\n",
    "            P[state] = ['L','R','D','U']\n",
    "    return V,R,P,states,terminal_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_evaluation(V,R,P,states,terminal_states):\n",
    "    '''\n",
    "    Arguments:\n",
    "            V is a 2d array initialized as 0\n",
    "            R is the array containing rewards for each state\n",
    "            P is the policy taken by the agent\n",
    "            states - array containing tuples of states in the gridworld\n",
    "            terminal_states - array containing terminal states of the gridworld\n",
    "    Returns:\n",
    "            V - The value function calculated for the policy P\n",
    "    '''\n",
    "    num_iterations = 0\n",
    "    V = {}\n",
    "    for state in states:\n",
    "        V[state] = 0\n",
    "    while num_iterations < 1000:\n",
    "        V1 = {}\n",
    "        for state in states:\n",
    "            V1[state] = 0\n",
    "        \n",
    "        for state in states:\n",
    "            if state in terminal_states:\n",
    "                continue\n",
    "            moves = len(P[state])\n",
    "            if 'L' in P[state]:\n",
    "                V1[state] += (R[state] + V[(state[0],max(0,state[1]-1))])/moves\n",
    "            if 'R' in P[state]:\n",
    "                V1[state] += (R[state] + V[(state[0],min(3,state[1]+1))])/moves\n",
    "            if 'U' in P[state]:\n",
    "                V1[state] += (R[state] + V[(max(0,state[0]-1),state[1])])/moves\n",
    "            if 'D' in P[state]:\n",
    "                V1[state] += (R[state] + V[(min(3,state[0]+1),state[1])])/moves    \n",
    "                    \n",
    "        V = V1\n",
    "        num_iterations += 1\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_improvement(V,R,P,P1,states,terminal_states):\n",
    "    '''\n",
    "    Arguments: \n",
    "            V is the value function\n",
    "            R is the array containing rewards for each state\n",
    "            P is the equiprobable random policy\n",
    "            P1 is the previous optimal policy\n",
    "            states - array containing tuples of states in the gridworld\n",
    "            terminal_states - array containing terminal states of the gridworld\n",
    "    Returns:\n",
    "            P - Optimal policy after performing policy improvement\n",
    "            policy_stable - bool variable denoting if P = P1\n",
    "    '''\n",
    "    policy_stable = True\n",
    "    # Iterate over all states to find the optimal policy\n",
    "    for state in states:\n",
    "        if state in terminal_states:\n",
    "            continue\n",
    "        optimal_policy = []\n",
    "        old_policy = P1[state]\n",
    "        max_val = -1e10\n",
    "        if 'L' in P[state]:\n",
    "            if state[1] - 1 >= 0:\n",
    "                val = R[state] + V[(state[0],max(0,state[1]-1))]\n",
    "                if val > max_val:\n",
    "                    max_val = val\n",
    "                    optimal_policy = ['L']\n",
    "                elif val == max_val:\n",
    "                    optimal_policy.append('L')\n",
    "\n",
    "        if 'R' in P[state]:\n",
    "            if state[1] + 1 < 4:\n",
    "                val = R[state] + V[(state[0],min(3,state[1]+1))]\n",
    "                if val > max_val:\n",
    "                    max_val = val\n",
    "                    optimal_policy = ['R']\n",
    "                elif val == max_val:\n",
    "                    optimal_policy.append('R')\n",
    "        \n",
    "        if 'U' in P[state]:\n",
    "            if state[0] - 1 >= 0:\n",
    "                val = R[state] + V[(max(state[0]-1,0),state[1])]\n",
    "                if val > max_val:\n",
    "                    max_val = val\n",
    "                    optimal_policy = ['U']\n",
    "                elif val == max_val:\n",
    "                    optimal_policy.append('U')\n",
    "                \n",
    "        if 'R' in P[state]:\n",
    "            if state[0] + 1 < 4:\n",
    "                val = R[state] + V[(min(3,state[0]+1),state[1])]\n",
    "                if val > max_val:\n",
    "                    max_val = val\n",
    "                    optimal_policy = ['D']\n",
    "                elif val == max_val:\n",
    "                    optimal_policy.append('D')\n",
    "        \n",
    "           # Check if policy for state V[state] has changed\n",
    "            if old_policy != optimal_policy:\n",
    "                policy_stable = False\n",
    "                \n",
    "            P[state] = optimal_policy\n",
    "            \n",
    "    return P,policy_stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial value function is: \n",
      "[[  0. -14. -20. -22.]\n",
      " [-14. -18. -20. -20.]\n",
      " [-20. -20. -18. -14.]\n",
      " [-22. -20. -14.   0.]]\n",
      "\n",
      "Optimal value function is: \n",
      "[[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -2.]\n",
      " [-2. -3. -2. -1.]\n",
      " [-3. -2. -1.  0.]]\n",
      "\n",
      "The optimal policy is:\n",
      "[[], ['L'], ['L'], ['L', 'D']]\n",
      "[['U'], ['L', 'U'], ['L', 'R', 'U', 'D'], ['D']]\n",
      "[['U'], ['L', 'R', 'U', 'D'], ['R', 'D'], ['D']]\n",
      "[['R', 'U'], ['R'], ['R'], []]\n"
     ]
    }
   ],
   "source": [
    "V,R,P1,states,terminal_states = initialization()\n",
    "V = policy_evaluation(V,R,P1,states,terminal_states)\n",
    "\n",
    "# Initial value function\n",
    "V1 = np.zeros((4,4))\n",
    "for state in states:\n",
    "    V1[state[0]][state[1]] = V[state]\n",
    "print(\"Initial value function is: \")\n",
    "print(V1)\n",
    "\n",
    "# Perform policy iteration until the policy doesn't change for any state in an iteration\n",
    "while True:\n",
    "    # Equiprobable random policy\n",
    "    P = {}\n",
    "    for state in states:\n",
    "        if not (state in terminal_states):\n",
    "            P[state] = ['L','R','U','D']\n",
    "        else:\n",
    "            P[state] = []\n",
    "\n",
    "    P1,policy_stable = policy_improvement(V,R,P,P1,states,terminal_states)\n",
    "    # If policy stable is true, the policy hasn't changed for any state in an iteration\n",
    "    if policy_stable:\n",
    "        break\n",
    "    V = policy_evaluation(V,R,P1,states,terminal_states)\n",
    "\n",
    "# Print optimal value function\n",
    "print(\"\\nOptimal value function is: \")\n",
    "V1 = np.zeros((4,4))\n",
    "for state in states:\n",
    "    V1[state[0]][state[1]] = V[state]\n",
    "print(np.round(V1))\n",
    "\n",
    "\n",
    "# Print optimal policy\n",
    "# Each cell denotes the optimal action that needs to be taken from that state\n",
    "P = [[[],[],[],[]],\n",
    "     [[],[],[],[]],\n",
    "     [[],[],[],[]],\n",
    "     [[],[],[],[]]]\n",
    "for v,a in P1.items():\n",
    "    P[v[0]][v[1]] = a\n",
    "print(\"\\nThe optimal policy is:\")\n",
    "for row in P:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
